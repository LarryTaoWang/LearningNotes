# Flink Application
## Real World Application

## Application Deployment
Flink Application can be deployed in two different styles.

### Framework style - Traditional Way
Flink applications are packaged into a **JAR file** and submitted by a client to **a running service**. The service can be a Flink Dispatcher, a Flink JobManager, or YARN’s ResourceManager, but finally handed to a Flink JobManager to be executed.

### Library style - for Microservices Architectures
In this mode, the Flink application is bundled in an application- specific container and a job-independent container.

* Application-specific container: container that launches the ResourceManager and JobManager and submits the bundled job for execution. 

* TaskManager container: container that starts a TaskManager, which connects to the ResourceManager and registers its slots.

# Architecture of Flink
When an application is submitted for execution, Flink’s components interact with each other as follow: 

![Application-submission-and-component-interactions](../images/Flink/Application-submission-and-component-interactions.jpg)

## Dispatcher
Dispatcher provides a **REST interface** to submit applications for execution. Once an application is submitted for execution, it starts a JobManager and hands the application over. 

A dispatcher might not be required in **TODO deployment mode** and the REST interface enables the dispatcher to serve as an HTTP entry point to clusters that are behind a firewall.

## JobManager
Each application is controlled by a different JobManager process, which 
* Converts the logical JobGraph into the physical ExecutionGraph
* Requests TaskManager slots from ResourceManager
* Distribute the tasks of the ExecutionGraph to the TaskManagers once it receives enough TaskManager slots
* Responsible for coordination during execution

## Resource Manager
The ResourceManager is responsible for managing **TaskManager slots**, Flink’s unit of processing resources: 
 * Instructs a TaskManager with idle slots to offer them to the JobManager, when a JobManager requests TaskManager slots 
 * Talk to a resource provider to provision containers when there are not enough slots
 * Terminate idle TaskManagers to free resources

Flink features multiple ResourceManagers for different environments and resource providers such as YARN, Mesos, Kubernetes, and standalone deployments. 

## Task Manager
TaskManagers are the worker processes of Flink. Typically, there are multiple TaskManagers running in a Flink setup. Each TaskManager provides a certain number of slots. The number of slots limits the number of tasks a TaskManager can execute. After it has been started, a TaskManager registers its slots to the ResourceManager. When instructed by the ResourceManager, the TaskManager offers one or more of its slots to a JobManager. The JobManager can then assign tasks to the slots to execute them. During execution, a TaskManager exchanges data with other TaskManagers that run tasks of the same application. The execution of tasks and the concept of slots is discussed in “Task Execution”.

A processing slot can execute one slice of an application—one parallel task of each operator of the application.

# Time Semantics
## Processing Time and Event Time
Definition: 
* Processing Time: the time of the local clock on the machine where the operator processing **the stream is being executed**
* Event time: the time when an event in the stream **actually happened**, based on a **timestamp**

Pros and Cons:
* Processing time: offers low latency but results depend on the speed of processing and are not deterministic
* event time guarantees deterministic results and allows you to deal with events that are late or even **out-of-order** messages.

## Timestamp
Flink encodes Event time timestamps as 16-byte **Long** values and attaches them as metadata to records. Its built-in operators interpret the Long value as a **Unix timestamp with millisecond precision**. Timestamps and watermarks are usually assigned and generated when a stream is **ingested** by a streaming application. 

User-defined timestamp assignment functions should be applied **as close to a source operator as possible** because it can be difficult to reason about the order of records and their timestamps after they have been processed by an operator. This is also the reason it is not a good idea to override existing timestamps and watermarks in the middle of a streaming application.

<!-- A Flink DataStream application can assign timestamps in three ways:

* **At the source**: Timestamps and watermarks can be assigned and generated by a SourceFunction when a stream is ingested into an application. A source function emits a stream of records. Records can be emitted together with an associated timestamp, and watermarks can be emitted at any point in time as special records. If a source function (temporarily) does not emit anymore watermarks, it can declare itself idle. Flink will exclude stream partitions produced by idle source functions from the watermark computation of subsequent operators. The idle mechanism of sources can be used to address the problem of not advancing watermarks as discussed earlier. Source functions are discussed in more detail in “Implementing a Custom Source Function”.

* Periodic assigner: The DataStream API provides a user-defined function called AssignerWithPeriodicWatermarks that extracts a timestamp from each record and is periodically queried for the current watermark. The extracted timestamps are assigned to the respective record and the queried watermarks are ingested into the stream. This function will be discussed in “Assigning Timestamps and Generating Watermarks”.

* Punctuated assigner: AssignerWithPunctuatedWatermarks is another user-defined function that extracts a timestamp from each record. It can be used to generate watermarks that are encoded in special input records. In contrast to the AssignerWithPeriodicWatermarks function, this function can—but does not need to—extract a watermark from each record. We discuss this function in detail in “Assigning Timestamps and Generating Watermarks” as well. -->

## Watermarks
Considering delayed or out-of-order messages, further events with timestamp less than T may be received at time T, then we can never decide when to trigger an event time window. This is why we need watermarks.

Watermarks are used to derive the **current event time** at each task in an event-time application and it has two properties:
* Must be monotonically increasing 
* A water mark with a timestamp T indicates that all subsequent records should have timestamps > T

Watermark is implemented as special records holding timestamp as a Long value and can be access only via DataStream API. Time-based operators use this time to trigger computations and make progress. 

Watermark can be used to control completeness and latency. Tight watermark -> low latency + low completeness; conservative watermark -> high latency + high completeness. 

## Late Data
Definition: When a task receives a record that violates the watermark property and has smaller timestamps than a previous received watermark, it may be that the computation it belongs to has already been completed

Flink provides different ways to deal with late records:
* TODO

## Watermark Propagation and Event Time
**A task maintains a partition watermark for each input partition.** When a task's partition receives a watermark:
1. The task updates its partition's internal event-time clock to be the maximum of the received watermark value and the current value
2. The task updates its event-time clock to be the minimum of all partition watermarks. 
3. If the event-time clock advances, the task processes all triggered timers and invokes a callback function that can perform a computation and emit records.
4. The task broadcasts its new event time to all downstream tasks by emitting a corresponding watermark to all connected output partitions.

The tasks of operators with two or more input streams such as Union or CoFlatMap compute their event-time clock as the minimum of all partition watermarks. 

An example is as follow:   
![Update-the-event-time-of-a-task-with-watermarks](../images/Flink/Update-the-event-time-of-a-task-with-watermarks.png)

# State

# Tasks in Detail
## Data Transfer Between Tasks
The tasks of a running application are continuously exchanging data. The TaskManagers take care of shipping data from sending tasks to receiving tasks. The network component of a TaskManager collects records in buffers before they are shipped,

Streaming applications need to exchange data in a pipelined fashion—each pair of TaskManagers maintains a permanent TCP connection to exchange data. 2 With a shuffle connection pattern, each sender task needs to be able to send data to each receiving task. A TaskManager needs one dedicated network buffer for each receiving task that any of its tasks need to send data to.

In order to enable a smooth pipelined data exchange, a TaskManager must be able to provide enough buffers to serve all outgoing and incoming connections concurrently. With a shuffle or broadcast connection, each sending task needs a buffer for each receiving task; the number of required buffers is quadratic to the number of tasks of the involved operators. Flink’s default configuration for network buffers is sufficient for small- to medium-sized setups.

## Credit-Based Flow Control
Sending individual records over a network connection is inefficient and causes significant overhead. Buffering is needed to fully utilize the bandwidth of network connections. In the context of stream processing, one disadvantage of buffering is that it adds latency because records are collected in a buffer instead of being immediately shipped.

Flink implements a credit-based flow control mechanism that works as follows. A receiving task grants some credit to a sending task, the number of network buffers that are reserved to receive its data. Once a sender receives a credit notification, it ships as many buffers as it was granted and the size of its backlog—the number of network buffers that are filled and ready to be shipped. The receiver processes the shipped data with the reserved buffers and uses the sender’s backlog size to prioritize the next credit grants for all its connected senders.

Credit-based flow control reduces latency because senders can ship data as soon as the receiver has enough resources to accept it. Moreover, it is an effective mechanism to distribute network resources in the case of skewed data distributions because credit is granted based on the size of the senders’ backlog. Hence, credit-based flow control is an important building block for Flink to achieve high throughput and low latency.

## JVM Related
A TaskManager executes its tasks multi-threaded in the same JVM process. Threads are more lightweight than separate processes and have lower communication costs but do not strictly isolate tasks from each other. Hence, a single misbehaving task can kill a whole TaskManager process and all tasks that run on it. By configuring only a single slot per TaskManager, you can isolate applications across TaskManagers. By leveraging thread parallelism inside a TaskManager and deploying several TaskManager processes per host, Flink offers a lot of flexibility to trade off performance and resource isolation when deploying applications.


